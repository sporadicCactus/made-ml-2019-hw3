{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train.pickle', 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_size_dict = dict()\n",
    "for qid, docs in dataset.items():\n",
    "    labels = np.array([doc[0] for doc in docs])\n",
    "    features = np.vstack([doc[1] for doc in docs])\n",
    "    sort_ind = np.flip(np.argsort(labels))\n",
    "    labels = labels[sort_ind].reshape(-1,1)\n",
    "    if labels.max() == labels.min():\n",
    "        continue\n",
    "    features = features[sort_ind]\n",
    "    if labels.shape[0] in data_by_size_dict.keys():\n",
    "        data_by_size_dict[labels.shape[0]][0].append(features)\n",
    "        data_by_size_dict[labels.shape[0]][1].append(labels)\n",
    "    else:\n",
    "        data_by_size_dict[labels.shape[0]] = ([features], [labels])\n",
    "keys = list(data_by_size_dict.keys())\n",
    "keys.sort()\n",
    "data_by_size = []\n",
    "for key in keys:\n",
    "    value = data_by_size_dict[key]\n",
    "    data_by_size.append((np.array(value[0]), np.array(value[1])))\n",
    "del data_by_size_dict\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = data_by_size[0][0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(data_list, test_size):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for data in data_list:\n",
    "        if len(data[0]) < 10:\n",
    "            test_list.append((torch.FloatTensor(data[0]).cuda(),\n",
    "                              torch.LongTensor(data[1]).cuda()))\n",
    "            continue\n",
    "        X_train, X_test = train_test_split(data[0], test_size = test_size, train_size=1 - test_size)\n",
    "        y_train, y_test = train_test_split(data[1], test_size = test_size, train_size=1 - test_size)\n",
    "        train_list.append((torch.FloatTensor(X_train).cuda(),torch.LongTensor(y_train).cuda()))\n",
    "        test_list.append((torch.FloatTensor(X_test).cuda(),torch.LongTensor(y_test).cuda()))\n",
    "    return train_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, test_list = tt_split(data_by_size, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935.1435546875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(model, data_list):\n",
    "    model = model.eval()\n",
    "    log2 = torch.tensor(np.log(2)).cuda()\n",
    "    acc_list = []\n",
    "    for batch in data_list:   \n",
    "        with torch.no_grad():\n",
    "            features = batch[0]\n",
    "            labels = batch[1]\n",
    "            scores = model.forward(features)\n",
    "            n_docs = labels.shape[1]\n",
    "            order = 1 + torch.sort(torch.sort(scores, dim=1, descending=True)[1], dim=1)[1]\n",
    "            true_order = torch.arange(1, labels.shape[1] + 1).reshape(-1,1)\\\n",
    "                .repeat(labels.shape[0],1,1).cuda()\n",
    "            explabel = torch.exp(labels*log2)\n",
    "            logorder = 1 / (torch.log(order.float()) + 1)\n",
    "            DCGmax = ((explabel - 1)/(torch.log(true_order.float()) + 1))\\\n",
    "                .sum(dim=1, keepdim=True)\n",
    "            DCG = ((explabel - 1)/(torch.log(order.float()) + 1)).sum(dim=1, keepdim=True)\n",
    "            acc_list.append((DCG.shape[0], ((DCG+0.001)/(DCGmax+0.001)).sum().item()))\n",
    "    acc = 0\n",
    "    total_queries = 0\n",
    "    for n_queries, nDCGsum in acc_list:\n",
    "        total_queries += n_queries\n",
    "        acc += nDCGsum\n",
    "    return acc/total_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_features, n_layers, layer_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        layer_struct = [layer_size for i in range(n_layers)]\n",
    "        layer_struct = [in_features] + layer_struct\n",
    "        for i in range(1, n_layers + 1):\n",
    "            self.layers.append(nn.Linear(layer_struct[i-1], layer_struct[i]))\n",
    "        self.out_layer = nn.Linear(layer_struct[-1], 1)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = x\n",
    "        for layer in self.layers:\n",
    "            y_pred = layer(y_pred)\n",
    "            y_pred = y_pred + torch.relu(y_pred)\n",
    "            y_pred = self.drop(y_pred)\n",
    "        y_pred = self.out_layer(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_features, 10, 500).cuda()\n",
    "curr_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14857\n",
      "12086\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(batch[0]) for batch in train_list]))\n",
    "print(sum([len(batch[0]) for batch in train_list[3:40]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.82256, test: 0.81799\n",
      "Train: 0.82295, test: 0.81802\n",
      "Train: 0.82293, test: 0.81793\n",
      "Train: 0.82300, test: 0.81838\n",
      "Train: 0.82331, test: 0.81834\n",
      "Train: 0.82329, test: 0.81840\n",
      "Train: 0.82339, test: 0.81811\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6ac3a6397026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mtest_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnDCG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train: {nDCG(model, train_list):.5f}, test: {test_metric:.5f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_metric\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcurr_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mcurr_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7dd162f51a76>\u001b[0m in \u001b[0;36mnDCG\u001b[1;34m(model, data_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mn_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-5def964cb42d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "log2 = torch.tensor(np.log(2)).cuda()\n",
    "epochs = 100\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for ep in range(epochs):\n",
    "    for batch in train_list[3:40]:\n",
    "        model.train()\n",
    "        features = batch[0]\n",
    "        labels = batch[1]\n",
    "        scores = model.forward(features)\n",
    "        n_docs = labels.shape[1]\n",
    "        with torch.no_grad():\n",
    "            order = 1 + torch.sort(torch.sort(scores, dim=1, descending=True)[1], dim=1)[1]\n",
    "            true_order = torch.arange(1, labels.shape[1] + 1).reshape(-1,1)\\\n",
    "                .repeat(labels.shape[0],1,1).cuda()\n",
    "            explabel = torch.exp(labels*log2)\n",
    "            logorder = 1 / (torch.log(order.float()) + 1)\n",
    "            DCGmax = ((explabel - 1)/(torch.log(true_order.float()) + 1)).sum(dim=1, keepdim=True)\n",
    "            dNDCGabs = ((logorder.repeat(1,1,n_docs) - logorder.repeat(1,1,n_docs).transpose(1,2)) * \\\n",
    "                (explabel.repeat(1,1,n_docs) - explabel.repeat(1,1,n_docs).transpose(1,2))).abs()/(0.01 + DCGmax)\n",
    "            dscores = scores.repeat(1,1,n_docs) - scores.repeat(1,1,n_docs).transpose(1,2)\n",
    "            smat = torch.sign(labels.repeat(1,1,n_docs) - labels.repeat(1,1,n_docs).transpose(1,2))\n",
    "            lambdaij = smat*torch.sigmoid(-smat*dscores)*dNDCGabs\n",
    "            lambdai = lambdaij.transpose(1,2).sum(dim=2) - lambdaij.sum(dim=2)\n",
    "        loss = (scores.view(-1,n_docs)*lambdai).sum()\n",
    "        loss = loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    test_metric = nDCG(model, test_list)\n",
    "    print(f'Train: {nDCG(model, train_list):.5f}, test: {test_metric:.5f}')\n",
    "    if test_metric > curr_test:\n",
    "        curr_test = test_metric\n",
    "        torch.save(model.state_dict(), 'temp.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDCG(model, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'net10x500_0.837.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('temp.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.pickle', 'rb') as file:\n",
    "    testset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "log2 = np.log(2)\n",
    "docs_processed = 0\n",
    "model.eval()\n",
    "filename = 'netsol_3.txt'\n",
    "with open('./'+filename, 'w') as file:\n",
    "    file.write('QueryId,DocumentId\\n')\n",
    "    for qid, docs in testset.items():\n",
    "        X = torch.tensor(np.vstack(tuple((doc[1] for doc in docs)))).cuda().float()\n",
    "        doc_ids = []\n",
    "        for doc in docs:\n",
    "            docs_processed += 1\n",
    "            doc_ids.append(docs_processed)\n",
    "        doc_ids = np.array(doc_ids).reshape(-1)\n",
    "        scores = model(X).reshape(-1)\n",
    "#         scores = torch.rand(len(doc_ids))\n",
    "        ordered_index = torch.sort(scores, descending=True)[1]\n",
    "        ordered_ids = doc_ids[ordered_index.cpu()].reshape(-1)\n",
    "        for i in range(len(ordered_ids)):\n",
    "            file.write(str(qid)+','+str(ordered_ids[i])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
